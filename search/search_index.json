{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This repository contains essential resources, scripts, and notes for learning and practicing AWS, especially for WorldSkills #53.</p>"},{"location":"#what-youll-find-here","title":"What You'll Find Here:","text":"<ul> <li>Scripts and code snippets for various AWS services.</li> <li>Practical examples and configurations.</li> <li>Key concepts and study notes for WorldSkills preparation.</li> </ul> <p>Feel free to explore and contribute!</p> <p>Contact: juliomacedo.vicente@gmail.com</p> <p>GitHub Repository: AWS Study</p>"},{"location":"CloudWatch/x-ray/","title":"AWS X-Ray Documentation","text":"<p>AWS X-Ray is a service that enables you to trace requests made to your application in distributed systems, making it easier to identify infrastructure issues and measure the time taken for each request. It is widely used in microservices-based applications.</p>"},{"location":"CloudWatch/x-ray/#what-is-aws-x-ray","title":"What is AWS X-Ray?","text":"<p>AWS X-Ray helps developers analyze and debug distributed applications, such as those built using a microservices architecture. With X-Ray, you can:</p> <ul> <li>Trace requests as they travel through your application.</li> <li>Identify bottlenecks and performance issues.</li> <li>Gain insights into the behavior of your application.</li> </ul>"},{"location":"CloudWatch/x-ray/#getting-started-with-aws-x-ray-in-python","title":"Getting Started with AWS X-Ray in Python","text":""},{"location":"CloudWatch/x-ray/#example-enabling-x-ray-for-popular-libraries","title":"Example: Enabling X-Ray for Popular Libraries","text":"<p>The following example demonstrates how to enable AWS X-Ray to automatically monitor popular libraries in your Python application:</p> <pre><code>from aws_xray_sdk.core import xray_recorder\nfrom aws_xray_sdk.core import patch_all\n\n# Enable X-Ray to monitor popular libraries automatically\npatch_all()\n</code></pre>"},{"location":"CloudWatch/x-ray/#using-x-ray-middleware","title":"Using X-Ray Middleware","text":"<p>X-Ray middleware integrates with HTTP requests in your application and can be used with frameworks like Flask, Django, etc.</p>"},{"location":"CloudWatch/x-ray/#example-flask-integration","title":"Example: Flask Integration","text":"<p>The example below shows how to integrate AWS X-Ray with a Flask application:</p> <pre><code>from flask import Flask\nfrom aws_xray_sdk.ext.flask.middleware import XRayMiddleware\nfrom aws_xray_sdk.core import xray_recorder\n\napp = Flask(__name__)\n\n# Configure the service name that will appear in X-Ray\nxray_recorder.configure(service='MyApplication')\n\n# Enable X-Ray middleware in Flask\nXRayMiddleware(app, xray_recorder)\n</code></pre> <p>This setup ensures that all routes in the Flask application are monitored by AWS X-Ray.</p>"},{"location":"CloudWatch/x-ray/#example-adding-custom-subsegments-in-flask","title":"Example: Adding Custom Subsegments in Flask","text":"<p>The following example demonstrates how to create a custom subsegment within a route in a Flask application:</p> <pre><code>from flask import Flask\nfrom aws_xray_sdk.ext.flask.middleware import XRayMiddleware\nfrom aws_xray_sdk.core import xray_recorder\nimport time\n\napp = Flask(__name__)\nxray_recorder.configure(service='MyApplication')\nXRayMiddleware(app, xray_recorder)\n\n# Default Flask route\n@app.route(\"/process\")\ndef process():\n    # Create a custom subsegment with a personalized name\n    with xray_recorder.in_subsegment('simulating-processing') as subsegment:\n        time.sleep(1.5)  # Simulate processing\n        subsegment.put_metadata('example_data', {'info': 'important value'}, 'custom')\n\n    return \"OK!\"\n</code></pre> <p>This example creates a manual subsegment with AWS X-Ray within a route, allowing you to add custom metadata and simulate processing.</p>"},{"location":"CloudWatch/x-ray/#best-practices-for-using-aws-x-ray","title":"Best Practices for Using AWS X-Ray","text":"<ol> <li>Use meaningful service names: Ensure that the service names configured in <code>xray_recorder</code> are descriptive and unique.</li> <li>Add custom metadata: Use subsegments to add metadata that can help debug specific parts of your application.</li> <li>Monitor performance: Regularly analyze traces to identify bottlenecks and optimize your application.</li> <li>Integrate with other AWS services: Combine X-Ray with services like CloudWatch for enhanced monitoring and alerting.</li> </ol>"},{"location":"CloudWatch/x-ray/#additional-resources","title":"Additional Resources","text":"<ul> <li>AWS X-Ray Documentation</li> <li>AWS SDK for Python (Boto3)</li> <li>Flask Documentation</li> </ul>"},{"location":"Coder/vscoder/","title":"Coder","text":""},{"location":"Coder/vscoder/#referencias","title":"Refer\u00eancias","text":"<ul> <li> Coder Server </li> <li> Script coder </li> </ul>"},{"location":"Coder/vscoder/#instalacao","title":"Instala\u00e7\u00e3o","text":"<pre><code>curl -fsSL https://code-server.dev/install.sh | sh\nsudo systemctl enable --now code-server@$USER\n</code></pre> <p>Dentro do arquivo config.yaml configure para o seu servidor <pre><code>vim /home/ubuntu/.config/code-server/config.yaml\n\nbind-addr: 0.0.0.0:8080 # escutando todas as interfaces\nauth: password\npassword: '$PASSWORD' # variavel de uma senha\ncert: false\n</code></pre></p> <p>Valida\u00e7\u00e3o <pre><code>sudo systemctl restart code-server@ubuntu\nsudo systemctl status code-server@ubuntu\n</code></pre></p>"},{"location":"k8s/Istio/","title":"Istio","text":""},{"location":"k8s/Istio/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Istio install</li> <li>Istioctl cmd</li> </ul>"},{"location":"k8s/Istio/#instalacao-via-helm","title":"Instala\u00e7\u00e3o via Helm","text":"<pre><code>helm repo add istio https://istio-release.storage.googleapis.com/charts\nhelm repo update\n</code></pre> <pre><code>helm upgrade --install istio-base istio/base -n istio-system --create-namespace\nhelm upgrade --install istiod istio/istiod -n istio-system\nhelm upgrade --install istio-ingress istio/gateway -n istio-ingress --create-namespace\n\nkubectl label namespace istio-ingress istio-injection=enabled\n</code></pre>"},{"location":"k8s/Istio/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>helm ls -n istio-system\nhelm ls -n istio-ingress\n</code></pre>"},{"location":"k8s/hpa/","title":"HPA \u2013 Horizontal Pod Autoscaler no Kubernetes","text":""},{"location":"k8s/hpa/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Metrics Server</li> <li>Documenta\u00e7\u00e3o HPA (K8s)</li> <li>Comando <code>kubectl autoscale</code></li> </ul>"},{"location":"k8s/hpa/#instalacao-do-metrics-server","title":"Instala\u00e7\u00e3o do Metrics Server","text":"<pre><code>kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n</code></pre>"},{"location":"k8s/hpa/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>kubectl top nodes\nkubectl top pods\n# Se aparecerem as m\u00e9tricas, est\u00e1 funcionando corretamente\n</code></pre>"},{"location":"k8s/hpa/#configuracao-recomendada","title":"Configura\u00e7\u00e3o recomendada","text":"<pre><code>kubectl edit deployment metrics-server -n kube-system\n</code></pre> <p>Adicione em <code>args</code>:</p> <pre><code>args:\n- --kubelet-insecure-tls\n- --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname\n</code></pre>"},{"location":"k8s/hpa/#manifesto-do-hpa","title":"Manifesto do HPA","text":"<pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: monitor-app-hpa\n  namespace: default\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: {{ .Values.deployment.name }}   # Nome do deployment (Helm)\n  minReplicas: 2\n  maxReplicas: 5\n  metrics:\n    - type: Resource\n      resource:\n        name: cpu\n        target:\n          type: Utilization\n          averageUtilization: 50        # Escala com uso acima de 50% da CPU\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: 70        # Escala com uso acima de 70% da Mem\u00f3ria\n</code></pre>"},{"location":"k8s/hpa/#gerar-hpa-via-comando","title":"Gerar HPA via comando","text":"<pre><code>kubectl autoscale deployment app-name --min=2 --max=10 --cpu-percent=70 --dry-run=client -o yaml &gt; hpa.yaml\n</code></pre>"},{"location":"k8s/hpa/#monitoramento-do-hpa","title":"Monitoramento do HPA","text":"<pre><code>kubectl get hpa -w    # Exibe o status em tempo real\n</code></pre>"},{"location":"k8s/hpa/#recurso-obrigatorio-no-deployment","title":"Recurso obrigat\u00f3rio no Deployment","text":"<p>O HPA s\u00f3 funciona se o Deployment definir corretamente os recursos (<code>resources:</code>). Indenta\u00e7\u00e3o errada = HPA n\u00e3o funciona (mostra \"unknown\")</p> <pre><code>spec:\n  containers:\n    - name: app\n      image: {{ .Values.image }}\n      ports:\n        - containerPort: 5000\n      resources:\n        requests:\n          cpu: \"100m\"\n          memory: \"64Mi\"\n        limits:\n          cpu: \"200m\"      # Normalmente nao se limita cpu do container\n          memory: \"128Mi\"\n</code></pre>"},{"location":"k8s/keda/","title":"KEDA \u2013 Kubernetes Event-Driven Autoscaling","text":""},{"location":"k8s/keda/#referencia","title":"Refer\u00eancia","text":"<ul> <li>Documenta\u00e7\u00e3o Oficial do KEDA</li> </ul>"},{"location":"k8s/keda/#instalacao-via-helm","title":"Instala\u00e7\u00e3o via Helm","text":"<pre><code>helm repo add kedacore https://kedacore.github.io/charts\nhelm repo update\nhelm install keda kedacore/keda --namespace keda --create-namespace\n</code></pre>"},{"location":"k8s/keda/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>kubectl get pods -n keda         # Verifica se o KEDA foi instalado\nkubectl get scaledobjects        # Lista objetos de escala aplicados\n</code></pre>"},{"location":"k8s/keda/#exemplo-de-scaledobject-por-uso-de-cpu","title":"Exemplo de ScaledObject por uso de CPU","text":"<pre><code>apiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: cpu-scaledobject\nspec:\n  scaleTargetRef:\n    name: {{ .Values.deployment.name }}   # Nome do deployment alvo (valor Helm)\n  minReplicaCount: 1\n  maxReplicaCount: 5                      # Sempre defina os limites\n  triggers:\n    - type: cpu\n      metadata:\n        type: Utilization\n        value: \"50\"                       # Escala se uso da CPU &gt; 50%\n</code></pre>"},{"location":"k8s/keda/#trigger-para-aws-sqs","title":"Trigger para AWS SQS","text":"<pre><code>triggers:\n  - type: aws-sqs-queue\n    metadata:\n      queueURLFromEnv: QUEUE_URL     # OU use diretamente 'queueURL'\n      queueLength: \"5\"               # Tamanho da fila para escalar (default: 5)\n      awsRegion: \"us-east-1\"         # Regi\u00e3o da fila\n      awsEndpoint: \"\"                # Opcional: endpoint customizado\n</code></pre>"},{"location":"k8s/promeGrafa/","title":"Setup Prometheus + Grafana no k8s","text":""},{"location":"k8s/promeGrafa/#referencias","title":"Refer\u00eancias","text":"<ul> <li>AWS Docs \u2013 Deploy Prometheus no EKS</li> <li>Artigo Medium \u2013 Prometheus + Grafana no K8s</li> </ul>"},{"location":"k8s/promeGrafa/#instalacao-via-helm","title":"Instala\u00e7\u00e3o via Helm","text":""},{"location":"k8s/promeGrafa/#adicionar-repositorios","title":"Adicionar reposit\u00f3rios","text":"<pre><code>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n</code></pre>"},{"location":"k8s/promeGrafa/#instalar-prometheus","title":"Instalar Prometheus","text":"<pre><code>helm install prometheus prometheus-community/prometheus \\\n  --namespace monitoring --create-namespace\n</code></pre>"},{"location":"k8s/promeGrafa/#instalar-grafana","title":"Instalar Grafana","text":"<pre><code>helm install grafana grafana/grafana \\\n  --namespace monitoring --create-namespace\n</code></pre>"},{"location":"k8s/promeGrafa/#validacao","title":"Valida\u00e7\u00e3o","text":"<pre><code>kubectl get all -n monitoring\n</code></pre>"},{"location":"k8s/promeGrafa/#acesso-via-port-forward","title":"Acesso via port-forward","text":""},{"location":"k8s/promeGrafa/#grafana","title":"Grafana","text":"<pre><code>kubectl port-forward svc/grafana 3000:80 -n monitoring\n</code></pre> <p>Acesse: http://localhost:3000 Usu\u00e1rio: <code>admin</code> Senha:</p> <pre><code>kubectl get secret grafana -n monitoring -o jsonpath=\"{.data.admin-password}\" | base64 --decode\n</code></pre>"},{"location":"k8s/promeGrafa/#prometheus","title":"Prometheus","text":"<pre><code>kubectl port-forward svc/prometheus-server 9090:80 -n monitoring\n</code></pre> <p>Acesse: http://localhost:9090</p>"},{"location":"k8s/promeGrafa/#instalacao-do-prometheus-e-grafana-com-node-selector","title":"Instala\u00e7\u00e3o do Prometheus e Grafana com Node Selector","text":""},{"location":"k8s/promeGrafa/#criar-arquivos-de-configuracao","title":"Criar arquivos de configura\u00e7\u00e3o","text":""},{"location":"k8s/promeGrafa/#prometheus-valuesyaml","title":"prometheus-values.yaml","text":"<pre><code>nodeSelector:\n  nodegroup: monitoring\n\nprometheus:\n  nodeSelector:\n    nodegroup: monitoring\n  service:\n    type: ClusterIP\n\nalertmanager:\n  nodeSelector:\n    nodegroup: monitoring\n\ngrafana:\n  nodeSelector:\n    nodegroup: monitoring\n</code></pre>"},{"location":"k8s/promeGrafa/#grafana-valuesyaml","title":"grafana-values.yaml","text":"<pre><code>nodeSelector:\n  nodegroup: monitoring\n\ngrafana:\n  additionalDataSources:\n    - name: Prometheus\n      type: prometheus\n      url: http://kube-prometheus-kube-prome-prometheus.monitoring.svc.cluster.local:9090\n      access: proxy\n      isDefault: true\n</code></pre>"},{"location":"k8s/promeGrafa/#comandos-de-instalacao","title":"Comandos de instala\u00e7\u00e3o","text":"<pre><code># Adicionar reposit\u00f3rios Helm\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-charts\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\n\n# Instalar Prometheus Stack\nhelm install kube-prometheus prometheus-community/kube-prometheus-stack \\\n  -f prometheus-values.yaml \\\n  --namespace monitoring \\\n  --create-namespace\n\n# Instalar Grafana  \nhelm install grafana grafana/grafana \\\n  -f grafana-values.yaml \\\n  --namespace monitoring \\\n  --create-namespace\n</code></pre>"},{"location":"k8s/promeGrafa/#verificar-instalacao","title":"Verificar instala\u00e7\u00e3o","text":"<pre><code>kubectl get pods -n monitoring -o wide\n</code></pre>"},{"location":"k8s/promeGrafa/#acessar-os-servicos","title":"Acessar os servi\u00e7os","text":"<p><pre><code># Prometheus\nkubectl port-forward -n monitoring pod/prometheus-kube-prometheus-kube-prome-prometheus-0 9090\n\n# Grafana\nkubectl port-forward svc/grafana 3000:80 -n monitoring\n</code></pre> Credenciais Grafana: - Usu\u00e1rio: admin - Senha: <code>kubectl get secret grafana -n monitoring -o jsonpath=\"{.data.admin-password}\" | base64 --decode</code> </p>"},{"location":"k8s/testCpu/","title":"Stress de CPU no Kubernetes","text":""},{"location":"k8s/testCpu/#referencias","title":"Refer\u00eancias","text":"<ul> <li>Artigo Medium</li> <li>Guia stress-ng</li> <li>Imagem Docker polinux/stress-ng</li> </ul>"},{"location":"k8s/testCpu/#namespace-para-o-teste","title":"Namespace para o teste","text":"<pre><code>kubectl create namespace monitor\n</code></pre>"},{"location":"k8s/testCpu/#manifesto-de-teste-cpu-stress","title":"Manifesto de teste (CPU Stress)","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: {{ .Values.test.name }}        # Nome vindo do values.yaml (Helm)\n  namespace: monitor\nspec:\n  containers:\n    - name: stress\n      image: polinux/stress-ng\n      command: [ \"stress-ng\" ]\n      args: [ \"--cpu\", \"2\", \"--cpu-method\", \"fft\", \"--timeout\", \"300s\" ]  \n      # Usa 2 CPUs com carga alta por 300 segundos (FFT)\n  restartPolicy: Never\n</code></pre>"},{"location":"k8s/testCpu/#aplicar-o-teste","title":"Aplicar o teste","text":"<pre><code>kubectl apply -f test-memory-cpu.yaml\n</code></pre>"},{"location":"k8s/testCpu/#validar-execucao","title":"Validar execu\u00e7\u00e3o","text":"<pre><code>kubectl get pods -n monitor\n</code></pre>"}]}